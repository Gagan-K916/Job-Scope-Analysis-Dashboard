{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d16d05c-0bc6-4862-b7b1-3f5038ec3b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5408\\789480327.py:12: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5408\\789480327.py:26: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  n_rows = sum(len(chunk) for chunk in pd.read_csv(file_path, chunksize=chunksize))\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5408\\789480327.py:34: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file_path, chunksize=chunksize):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, save_npz\n",
    "\n",
    "file_path = 'cleaned_data_naukri.csv'\n",
    "chunksize = 1000  \n",
    "unique_skills = set()\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "    chunk['Skills Required'] = chunk['Skills Required'].astype(str).str.split(',')\n",
    "    unique_skills.update(skill.strip() for sublist in chunk['Skills Required'] for skill in sublist)\n",
    "unique_skills = sorted(unique_skills)\n",
    "\n",
    "unique_skills.append('ExtraColumn') \n",
    "\n",
    "\n",
    "skill_to_index = {skill: idx for idx, skill in enumerate(unique_skills)}\n",
    "\n",
    "\n",
    "n_rows = sum(len(chunk) for chunk in pd.read_csv(file_path, chunksize=chunksize))\n",
    "n_cols = len(unique_skills)\n",
    "sparse_matrix = lil_matrix((n_rows, n_cols), dtype=np.int8)\n",
    "\n",
    "\n",
    "row_offset = 0\n",
    "\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "    chunk['Skills Required'] = chunk['Skills Required'].astype(str).str.split(',')\n",
    "    for i, skills_list in enumerate(chunk['Skills Required']):\n",
    "        for skill in skills_list:\n",
    "            if skill.strip() in skill_to_index:\n",
    "                sparse_matrix[row_offset + i, skill_to_index[skill.strip()]] = 1\n",
    "            else:\n",
    "                # Handle cases where skill doesn't exist in skill_to_index\n",
    "                sparse_matrix[row_offset + i, skill_to_index['ExtraColumn']] = 1\n",
    "                print(f\"Skill '{skill.strip()}' not found in skill_to_index. Adding to ExtraColumn.\")\n",
    "    row_offset += len(chunk)\n",
    "\n",
    "\n",
    "sparse_matrix = sparse_matrix.tocsr()\n",
    "save_npz('skills_sparse_matrix.npz', sparse_matrix)\n",
    "\n",
    "\n",
    "pd.Series(unique_skills).to_csv('unique_skills1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5836c7a6-fd5f-41ca-a6fe-f98dc58b8880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_5408\\3394139817.py:5: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('transformed_jobs_skills.csv')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch: 890 columns in matrix vs 38911 unique skills",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m unique_skills \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_skills.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Ensure the number of columns in the sparse matrix matches the number of unique skills\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sparse_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(unique_skills), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msparse_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns in matrix vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(unique_skills)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unique skills\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Convert sparse matrix to DataFrame\u001b[39;00m\n\u001b[0;32m     15\u001b[0m skills_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mfrom_spmatrix(sparse_matrix, columns\u001b[38;5;241m=\u001b[39munique_skills)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Mismatch: 890 columns in matrix vs 38911 unique skills"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "df = pd.read_csv('cleaned_data_naukri.csv')\n",
    "sparse_matrix = load_npz('skills_sparse_matrix.npz')\n",
    "unique_skills = pd.read_csv('unique_skills.csv', header=None).squeeze().tolist()\n",
    "assert sparse_matrix.shape[1] == len(unique_skills), f\"Mismatch: {sparse_matrix.shape[1]} columns in matrix vs {len(unique_skills)} unique skills\"\n",
    "skills_df = pd.DataFrame.sparse.from_spmatrix(sparse_matrix, columns=unique_skills)\n",
    "result_df = pd.concat([df, skills_df], axis=1)\n",
    "result_df.to_csv('transformed_jobs_skills.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
